{
    "identity": "pex-1687",
    "title": "<p>Analysis plan for primary cohort GWAS for blood lipid levels for the Global Lipids Genetics Consortium</p>",
    "content": [
        {
            "header": "Introduction",
            "content": ""
        },
        {
            "header": "Reagents",
            "content": ""
        },
        {
            "header": "Equipment",
            "content": ""
        },
        {
            "header": "Procedure",
            "content": "Global Lipids Genetics/GIANT Consortium HRC and 1KG phase3 Imputation and Analysis plan version 2\nUpdated: April 27, 2017 (v2a) to include non-HDL-cholesterol and some minor tweaks but analysis results generated using the March 17, 2017 plan (v2) are also acceptable.\u00a0All changes since March 17, 2017 are highlighted in yellow.\nPlan originally drafted by Xueling Sim, Heather Highland, and Scott Vrieze, modified by GIANT 1KG/HRC working group and Global Lipids Genetics Consortium HRC imputation working group, including Adam Locke and Sailaja Vedantam. If you have questions, please reply to the group CCed on the email accompanying this plan.\nOverview\nThere are three major components to this analysis plan:\n1)\u00a0\u00a0\u00a0\u00a0Genome-wide genotypes must be on the correct build (37/hg19) and correct strand (forward).\n2)\u00a0\u00a0\u00a0\u00a0For ALL studies, imputation of genotypes is performed using the 1KG phase 3 (if you have not already done so) and, for studies with samples of European-ancestry, also to the large haplotype panel from the Haplotype Reference Consortium. If you have already imputed to a different large haplotype panel (e.g. UK10K) please contact us.\n3)\u00a0\u00a0\u00a0\u00a0Association analysis is conducted using specific software tools that will provide all necessary summary statistics for flexible central meta-analysis.\nThis coordinated plan between Global Lipids and GIANT is meant to reduce the burden on primary analysts. We welcome you to join one or both consortia.\u00a0We thank you for your participation in past projects, and particularly welcome studies that are new to either consortia.\nSoftware\nBelow is a list of the software you will need to complete this analysis plan. For some tools using the specific version listed may be important.\nPhasing algorithms such as SHAPEIT, Eagle, HapiUR, and Minimac are only necessary if you\u2019re conducting imputation in-house, rather than using an imputation server. We provide generic instructions and instructions specific for the University of Michigan imputation server. Some may have used or be using other servers (e.g. the Sanger server); please contact them for instructions specific to that imputation server.\nrvTests (20170210):\nhttps://github.com/zhanxw/rvtests\n/releases\nBGZIP and tabix (0.2.6):\nhttp://samtools.sourceforge.net/tabix.shtml\nBcftools (1.3.1): http://www.htslib.org/download\nVcftools (0.1.8):\nhttps://github.com/vcftools/vcftools\nPLINK1.9 (Plink2):\nhttps://www.cog-genomics.org/plink2\n1. Genotypes\nArray\nAll studies must have some version of a genome-wide array, for example with >200,000 genome-wide common variants. Targeted arrays with limited/incomplete coverage of the genome (e.g. MetaboChip, ImmunoChip, Exome Chip, etc.) should not be used unless merged with a genome-wide array. If you are unsure, please contact Joel and/or Cristen for specific advice.\nIndividual studies should provide information in the Excel spreadsheet about the manufacturer and version of the array(s) they are using.\nQC should be done separately for individual studies, for major continental ancestries within a study, and also separately for samples of the same study that were genotyped on different arrays.\nGenotype QC\nTypical pre-imputation QC criteria:\nThese are some steps that we recommend for sample QC. Additional QC steps may be needed and should be determined by the local analysts for each study. Studies should provide a brief description of QC criteria in the Excel sheet.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Sample call rate (cut off >95% threshold recommended)\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Exclude samples with heterozygosity > median + 3*IQR\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Remove gender mismatches\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Remove duplicates\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Remove PCA outliers using a PCA projection of the study samples onto 1KG reference samples.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Hardy-Weinberg p>10\n-6\n, SNP call rate \u226598%\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Remove monomorphic markers\nAdditional QC will be conducted centrally at the meta-analysis stage.\nPrepare files for imputation\nThe \u201cHRC/1KG Imputation Preparation and Checking Tool\u201d developed by Will Rayner will check input data for accuracy relative to expected HRC or 1000G inputs prior to imputation.\nThis process will identify errors in your input data, including incorrect REF/ALT designations, incorrect strand designations, extreme deviations from expected allele frequencies, and palindromic (A/T and G/C) SNPs with allele frequency near 0.5 that are often the source of imputation errors, and generates commands to make files that have fixed or removed these problematic variants.\nThe tool can be downloaded here:\nhttp://www.well.ox.ac.uk/~wrayner/tools/HRC-1000G-check-bim.v4.2.5.zip\nThe tool requires site lists from the reference panels for comparison, which are available for download at the following locations:\nHRC:\nftp://ngs.sanger.ac.uk/production/hrc/HRC.r1-1/HRC.r1-1.GRCh37.wgs.mac5.sites.tab.gz\n(then unzipped with gunzip)\n1000G Phase 3:\nhttp://www.well.ox.ac.uk/~wrayner/tools/1000GP_Phase3_combined.legend.gz\n(then unzipped with gunzip)\nThe tool also requires frequency files from plink, which can be created as follows:\nplink --bfile\n--freq --out input_file_prefix\nWith these input files the tool can be run as follows:\nHRC:\nperl HRC-1000G-check-bim.pl -b\n-f\n-r HRC.r1-1.GRCh37.wgs.mac5.sites.tab \u2013h\n1000G:\nperl HRC-1000G-check-bim.pl -b\n-f\n-r 1000GP_Phase3_combined.legend -g -p\n(ALL, EUR, AFR, AMR, SAS, EAS are the relevant options for the \u2013p\nparameter, with ALL as default)\nThe perl script automatically produces a shell-script called\nRun-plink.sh.\nThe shell script contains a set of plink commands that\nshould be run to update or remove SNPs based on the checks and to create one updated binary plink file per chromosome. For this, the paths to the original study binary file should be adjusted in the shell script and the script should be started by typing ./\nRun-plink.sh\nat the command prompt.\nThe cleaned/updated binary files (one for each chromosome) generated by this tool should be ready for upload to the imputation server below after changing them to VCF format using plink2, bgzip and tabix in the UNIX environment:\nfor i in `seq 1 23`;\ndo\nplink --bfile Study-updated-chr${i} --keep-allele-order --recode vcf-iid --out Study-updated-chr${i}\nbgzip Study-updated-chr${i}.vcf\ntabix \u2013p vcf Study-updated-chr${i}.vcf.gz\ndone\n2. Imputation\nThere are two ways to conduct imputation: a) an Imputation Server or b) in-house imputation. The following instructions provide detailed instructions for imputation with the Michigan Imputation Server, but others such as the Sanger server are also acceptable. We recommend you use an imputation server if possible.\nNote\n: If you prefer, the imputation server has a \u2018Quality Control only\u2019 option you can use prior to imputation to ensure that no samples will be eliminated during imputation of autosomes or X chromosome.\nIf you run \u2018QC and imputation\u2019, and samples are removed (e.g., due to gender discordance), please make sure that number and order of samples in the X chromosome and autosomes will match as described in section 2.3.\nAncestry of samples and imputation panels:\nWe ask all studies that have not imputed to 1KG phase 3 to use the imputation server to do so. In addition, for studies with individuals of European-ancestry, we ask that they\nalso\nuse the imputation server to impute using the HRC panel.\nPhasing\nThe imputation server will automatically determine if you provide phased or unphased VCF files. We encourage re-phasing using Eagle (which is implemented by the imputation server). If you would like to provide phased haplotypes please convert them to VCF format.\nAn example command to convert haplotype format of HAPS/SAMPLE files from SHAPEIT to VCF would be:\nshapeit \u2013convert \u2013input-haps study.phased \u2013output-vcf\u00a0study-phased.vcf\n2.1. Impute to 1KG phase 3 panel\nThe 1KG phase 3 samples has both European and non-European samples and includes SNPs, indels, and CNVs. To capture these additional markers, and to provide a common reference panel across all samples, we ask that ALL studies, regardless of ancestry, impute to 1KG phase 3.\nPlease upload VCF files (phased or non-phased). Then select the following options:\n\u00b7\nReference Panel: 1000G Phase3 v5\n\u00b7\nPhasing:\nEagle v2.3\n\u00b7\nPopulation:\nas appropriate for the study (used only for quality control purposes)\n\u00b7\nMode:\nQuality Control & Imputation\nNote: Chromosome X will need to be imputed separate from other chromosomes after reformatting plink code 23 to X in the VCF file. Currently, SHAPEIT is the only available method for phasing chrX.\nSee below for detailed instructions on using the imputation server.\n2.2. Impute to HRC reference panel\nThe Haplotype Reference Consortium (HRC) has assembled over 60,000 haplotypes by combining together sequencing data from multiple cohorts (http://www.haplotype-reference-consortium.org). Impute all individuals of European ancestry using the HRC panel.\nPlease upload VCF files. Then select the following options:\n\u00b7\nReference Panel:\nHRC r1.1 2016\n\u00b7\nPhasing:\nEagle v2.3\n\u00b7\nPopulation:\nEUR (this parameter is for quality control purposes)\n\u00b7\nMode:\nQuality Control & Imputation\nNOTE: Chromosome X will need to be imputed separately from other chromosomes after reformatting plink code 23 to X in the VCF file. Currently, SHAPEIT is the only available method for phasing chrX.\nUsing the imputation server\nThe Michigan Imputation Server is available at\nhttps://imputationserver.sph.umich.edu\n. The server uses standard encryption (SSL or SFTP) to help ensure that genotypes are encrypted during upload and download. It does a few things automatically:\n1. Ensures we are all imputing to the exact same reference panel.\n2. Automatically performs quality checks (alleles, MAFs, SNP names, etc.)\n3. It phases and imputes, at no cost to the user in either computational time or analyst time.\nUploading VCF files\nMake an account and follow the instructions on the website. You will upload VCF genotype files to the server (only VCF file format is supported; instructions on converting to VCF are contained on the imputation server website under \u201cHelp\u201d and above in the chapter \u201cPrepare files for imputation\u201d).\nOne VCF file must be submitted for each chromosome.\nDownloading your imputed genotypes, info files, and QC report\nWhen imputation has finished you will receive an email alert. The imputation server will automatically encrypt all your imputed genotypes (for protection during download). The password to decrypt the files will be in the email notification, so don\u2019t delete that email!\nWhen you download your imputed genotypes please be sure to download all available files (the qcreport, statistics, zip files, and all the log files). We will ask that you submit most of these files to us along with all other files generated as part of this analysis plan.\nPlease do a quick check of the qcreport.html and statistics.txt files before proceeding with the analysis plan. If you are unsure of your imputation quality, please contact us. You will also upload these files to the server (see 8c).\nX chromosome\nNOTES on chromosome X:\n1) If the server detects sex discrepancy between genotypes and the provided PED file, discordant samples will be removed automatically prior to phasing and imputation. You will need to resolve these discrepancies genome-wide before proceeding with analysis.\n2) You will receive two output VCF files for chromosome X, one for males and one for females. You will need to merge these into a single chrX VCF.\nBoth of these issues are addressed below in section 2.3.\nImputation In-House\nIf you have chosen to use an imputation server, then you can ignore this step.\nSome studies will not be able to use the imputation server, for example if original participant consents forbid it. These studies will have to conduct imputation on their own. Please contact us if you need assistance.\n2.3. Post-imputation sample harmonization and variant pruning\nThere are a few post-imputation processing steps that are necessary prior to analysis.\nA. Harmonize samples and samples order between autosomes and chromosome X\nAs mentioned above, chrX imputation may have different numbers and order of samples from the autosomes due to automated filtering on the imputation server. You need to reconcile these possible discrepancies before creating a single whole genome VCF file, which will be used to create a genomic relationship matrix (kinship matrix) for the linear mixed model. If the sets of samples are not identical between the X and autosome VCFs (most likely because possibly sex-discordant samples were dropped during imputation of the X) you will need to eliminate any samples present only in autosome or X VCFs, and then reorder the samples in the X chromosome VCF file. The following bcftools commands 1) make a list of samples IDs in the chr22 VCF, 2) merges the male and female chrX VCFs and reorders the resulting chrX VCF according to the order of samples in chr22, then 3) generates an ordered list of IDs from chrX. Compare the two ID lists to confirm they are identical before proceeding.\u00a0Note that some cohorts have a small number of males who are heterozygous at many X chromosome markers outside the pseudoautosomal region.\u00a0Because these create problems later in analysis, we recommend removing these individuals as well, in addition to sex-discordant individuals.\n1)\nbcftools query -l chr22.dose.vcf.gz > ID_order_autosomes.txt\n2)\nbcftools merge chrX.no.auto_male.dose.vcf.gz chrX.no.auto_female.vcf.gz \u2013m both -O u | bcftools view -S ID_order_autosomes.txt --force-samples -O z > ChrX.combined.reorder.vcf.gz\n3)\nbcftools query \u2013l chrX.combined.reorder.vcf.gz > ID_order_chrX.txt\nIf there are samples in the autosomal files that do not appear in the chrX imputed VCFs, then bcftools will report a warning message:\nWarn: subset called for sample that does not exist in header: [ID] \u2026 skipping\nIt then proceeds to reorder the file, omitting these observations. If you encounter this message, you will need to use the sample list file ID_order_chrX.txt to select the overlapping samples when creating the polymorphic datasets in section B below.\nIf you do\nNOT\nreceive the warning message, please check that the sample list files ID_order_chrX.txt and ID_order_autosomes.txt are exactly the same (in content and order). If these two files are identical, you may proceed without the sample selection option in section B. This will speed up the operation of bcftools in section B.\nB. Create a list of monomorphic sites and subset polymorphic variants\nThese reference panels impute a great many variants into your samples, the vast majority of which are rare, and many will not be polymorphic in your sample. To minimize the size of output files in the association analyses below, we ask that you remove all monomorphic sites (monomorphic defined as at least one variant hard call genotype) from input VCF files prior to analysis. In conjunction, we ask that you upload a list of the variants that you drop in this process. The following commands with bcftools will generate both the list of monomorphic SNPs and the pruned VCF files.\n#Generate lists of monomorphic sites\n#!/bin/bash\nfor i in `seq 1 22`;\ndo\nbcftools view -q1.0:major \u2013S ID_order_chrX.txt chr${i}.dose.vcf.gz \u2013O u | bcftools query -f '%CHROM\\t%POS\\t%REF,%ALT\\n' >> STUDY_PANEL_ANALYST_imputed.monomorphic.txt\ndone\n#Generate VCFs with only polymorphic variants\n#!/bin/bash\nfor i in `seq 1 22`;\ndo\nbcftools view \u2013c 1:minor \u2013S ID_order_chrX.txt chr${i}.dose.vcf.gz\u00a0-O z > chr${i}.imputed.poly.vcf.gz\ntabix -p vcf chr${i}.imputed.poly.vcf.gz\ndone\n#Also run commands for merged chrX, which won\u2019t follow the pattern for the loop.\n3. Phenotype definition, covariate adjustment, and trait transformation\nALL TRAITS ARE INVERSE NORMAL TRANSFORMED AFTER CREATION OF RESIDUALS TO FACILITATE PROPER ANALYSIS OF LOW FREQUENCY VARIANTS\nThe rank-based inverse normal transformation of the residuals can be performed as below; alternatively, rvtests can automatically perform inverse normalization for covariate-adjusted trait residuals (instructions for this are in section 4.D. under Genotype-Phenotype Associations).\nin SAS:\nproc rank data=mydata out=inv normal=blom var &trait\nrun;\nin R:\n#if you have missing data\ny <- qnorm((rank(x,na.last=\"keep\u201d)-0.5)/sum(!is.na(x)))\nin STATA:\npctile pvariable = variable, nquantiles(N+1)\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0genp(percent_variable)\ngen inv_normal_variable=invnormal(percent_variable/100)\n(Where N is number of observations)\n3A. Lipid Traits\nPhenotypes:\nWe will analyze fasting lipid values using two different trait distributions: raw values and after inverse normal transformation. If you only have non-fasting levels then you can contribute to all four lipids analyses, but your study may be excluded from some analyses.\n(i.a) Total cholesterol (mg/dl; inverse normal)\n(i.b) Total cholesterol\u00a0(mg/dl; raw trait)\n(ii.a) High-density lipoprotein (HDL) cholesterol (mg/dl; inverse normal)\n(ii.b) High-density lipoprotein (HDL) cholesterol (mg/dl; raw trait)\n(iii.a) Low-density lipoprotein (LDL) cholesterol\n(inverse normal)\n(iii.b) Low-density lipoprotein (LDL) cholesterol (inverse normal)\n(iv.a) Triglycerides (mg/dl; natural log -> inverse normal)\n(iv.b) Triglycerides (mg/dl; natural log transformed)\n(v.a) Non-HDL cholesterol (nonhdlc) (TC-HDL; mg/dl; natural log -> inverse normal)\n(v.b) Non-HDL cholesterol (nonhdlc (TC-HDL; mg/dl; natural log transformed)\nIf you have both fasting and non-fasting measurements on the same individuals:\nplease use the fasting measurement.\nIf you have both fasting and non-fasting measurements in different individuals:\nFor LDL cholesterol and triglycerides, analyses should be carried out in fasting and non-fasting blood measurements separately. For total cholesterol and HDL cholesterol, fasting and non-fasting samples can be analyzed together.\nFor longitudinal studies, please use the baseline exam or earliest exam with fasting measures. Values should be in mg/dl.\nExclusions:\n\u00b7\nAdults over age 18 should be analyzed separately from children under age 18.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Exclude known Mendelian cases or obvious outliers likely to be data errors.\nPerform phenotypic modeling separated by:\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Race/ethnicity/ancestry\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Sex\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Disease status if appropriate: analyze cases and controls separately if the phenotype is correlated with disease status.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Adult/child status\n(i) Total Cholesterol\nPhenotype adjustment (prior to regression)\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Data collected before 1994 \u2013 no lipid medication adjustment\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Data collected after 1994 \u2013 for subjects on lipid medication replace TC by TC/0.8\n(i.a) Inverse normal transformed\nModel: Generate residuals and inverse normal transform in men and women separately\u00a0and separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have MenCase, MenControl, WomenCase, WomenControl, SexCombinedCase, and SexCombinedControl). For the sex combined analyses, combine the \u201cmen-specific_TC_INV\u201d and women-specific_TC_INV\u201d phenotype values to analyze together (all_TC_INV).\nTotal cholesterol (raw trait value in mg/dl for men) = age + age\n2\n+ PCs (+ other study specific covariates as needed) -> residuals -> inverse normal transformation (men-specific_TC_INV).\nNOTE: GLGC requests that you include ~4 PCs as study-specific covariates.\n(i.b) Raw trait\nModel: Only sex-combined. Generate residuals with sexes combined, but separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have SexCombinedCase and SexCombinedControl).\nTotal cholesterol (raw trait value in mg/dl) = age + age\n2\n+ sex + PCs (+ other study specific covariates as needed) -> residuals\u00a0(TC_RAW)\nNOTE: GLGC requests that you include ~4 PCs as study-specific covariates.\n(ii) High-density lipoprotein (HDL) Cholesterol\n(ii.a) Inverse normal transformed\nModel: Generate residuals and inverse normal transform in men and women separately and separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have MenCase, MenControl, WomenCase, WomenControl, SexCombinedCase, and SexCombinedControl). For the sex-combined analyses, combine the \u201cmen-specific_HDL_INV\u201d and women-specific_HDL_INV\u201d phenotype values to analyze together (all_HDL_INV).\nHDL cholesterol (raw trait value in mg/dl) = age + age\n2\n+ PCs (+ other study specific covariates as needed) -> residuals -> inverse normal transformation (HDL_INV)\nNOTE: GLGC requests that you include ~4 PCs as study-specific covariates.\n(ii.b) Raw trait\nModel: Only sex-combined. Generate residuals with sexes combined, but separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have SexCombinedCase and SexCombinedControl).\nHDL cholesterol (raw trait value in mg/dl) = age + age\n2\n+ sex + PCs (+ other study specific covariates as needed) -> residuals\u00a0(HDL_RAW)\nNOTE: GLGC requests that you include ~4 PCs as study-specific covariates.\n(iii) Low-density lipoprotein (LDL) Cholesterol\nPhenotype adjustment (prior to regression)\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0If not measured, LDL cholesterol can be calculated using the Friedewald equation for those with TG < 400 mg/dl\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0LDL = TC \u2013 HDL \u2013 (TG/5); if TC modified as described above for medication use after 1994, the modified TC is used in this formula.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0If LDL was measured after 1994 (measured and not estimated by Friedewald), then adjust LDL values for individuals taking lipid-lowering medication by using LDL/0.7 to approximate pre-medication LDL levels.\n(iii.a) Inverse normal transformed\nModel: Generate residuals and inverse normal transform in men and women separately and separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have MenCase, MenControl, WomenCase, WomenControl, SexCombinedCase, and SexCombinedControl). For the sex combined analyses, combine the \u201cmen-specific_LDL_INV\u201d and women-specific_LDL_INV\u201d phenotype values to analyze together (all_LDL_INV).\nLDL cholesterol (raw trait value in mg/dl) = age + age\n2\n+ PCs (+ other study specific covariates as needed) -> residuals -> inverse normal transformation (LDL_INV)\nNOTE: GLGC requests that you include ~4 PCs as study-specific covariates.\n(iii.b) Raw trait\nModel: Only sex-combined. Generate residuals with sexes combined, but separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have SexCombinedCase and SexCombinedControl).\nLDL cholesterol (raw trait value in mg/dl) = age + age\n2\n+ sex + PCs (+ other study specific covariates as needed) -> residuals\u00a0(LDL_RAW)\nNOTE: GLGC requests that you include ~4 PCs as study-specific covariates.\n(iv) Triglycerides\n(iv.a) Natural log + inverse normal transformed\nModel: Generate residuals and inverse normal transform in men and women separately and separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have MenCase, MenControl, WomenCase, WomenControl, SexCombinedCase, and SexCombinedControl). For the sex combined analyses, combine the \u201cmen-specific_logTG_INV\u201d and women-specific_logTG_INV\u201d phenotype values to analyze together (all_logTG_INV).\nln(raw Triglycerides trait value in mg/dl) = age + age\n2\n+ PCs (+ other study specific covariates as needed) -> residuals -> inverse normal transformation (logTG_INV)\nNOTE: GLGC requests that you include ~4 PCs as study-specific covariates.\n(iv.b) Natural log transformed\nModel: Only sex-combined. Generate residuals with sexes combined, but separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have SexCombinedCase and SexCombinedControl).\nln(raw Triglycerides trait value in mg/dl) = age + age\n2\n+ sex + PCs (+ other study specific covariates as needed) -> residuals\u00a0(logTG_RAW)\nNOTE: GLGC requests that you include ~4 PCs as study-specific covariates.\n(v) Non-HDL cholesterol\nUse medication-adjusted TC generated in i) and subtract HDL-cholesterol\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Data collected before 1994 \u2013 no lipid medication adjustment\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Data collected after 1994 \u2013 for subjects on lipid medication replace TC by TC/0.8\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Non-HDL = TC (adjusted) \u2013 HDL\n(v.a) Inverse normal transformed\nModel: Generate residuals and inverse normal transform in men and women separately and separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have MenCase, MenControl, WomenCase, WomenControl, SexCombinedCase, and SexCombinedControl). For the sex combined analyses, combine the \u201cmen-specific_nonHDL_INV\u201d and women-specific_nonHDL_INV\u201d phenotype values to analyze together (all_nonHDL_INV).\nNon-HDL cholesterol (raw trait value in mg/dl for men) = age + age\n2\n+ PCs (+ other study specific covariates as needed) -> residuals -> inverse normal transformation (men-specific_nonHDL_INV).\n(v.b) Raw trait\nModel: Only sex-combined. Generate residuals with sexes combined, but separately by case status if appropriate (e.g. where disease status is correlated with cholesterol you will have SexCombinedCase and SexCombinedControl).\nNon-HDL cholesterol (raw trait value in mg/dl) = age + age\n2\n+ sex + PCs (+ other study specific covariates as needed) -> residuals\u00a0(nonHDL_RAW)\n4. Genotype-phenotype association\nA. Group samples for analysis\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Please analyze major ancestry groups separately.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0We anticipate that some studies will have data from multiple genotyping arrays on samples from the same cohort. We expect there will likely be three typical situations:\no\u00a0\u00a0No sample overlap: analyze studies separately (batches with reasonably similar arrays can be analyzed together, using the array type as a covariate).\no\u00a0\u00a0All samples overlap: either a) select 1 array for imputation or ideally b) merge genotypes prior to imputation and perform a single analysis.\no\u00a0\u00a0Partial but significant overlap of samples - contact us, if needed, to customize a plan. The goal should be to upload sets of results from non-overlapping samples that can be combined in meta-analysis.\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0If a set of samples being analyzed together is particularly large (for example, N>30000), the association plan may need to be modified.\u00a0Please contact us to discuss further if this is the case.\nB. Perform association analyses\nAlways test additive models using linear regression, using a method that accounts for genotype imputation uncertainty, and also accounting for known or cryptic relatedness (see below).\u00a0Please indicate in your submission README file what method you have used for association analysis.\nEach individual study will perform data quality control (QC) and analysis and provide summary results for meta-analysis. Results files will be deposited to a central repository (details are provided below) where QC/data cleaning and meta-analysis will be performed.\nWe request association analyses be carried out using rvtests (version 20170210).\nThis software can be used for samples that include families or when an empirical kinship matrix is required for analysis. The input files required (phenotype, covariates) for rvtests are compatible with PLINK formats. It also calculates Hardy-Weinberg p-value and call rate for quality control purposes. We ask each study to generate kinship matrices (one for the autosomes and one for chromosome X) and fit linear mixed models to deliver single variant analysis results for the additive model.\u00a0Documentation for rvtests can be found here:\nhttps://github.com/zhanxw/rvtests\nIf you are unable to use a linear mixed model for some reason, please correct for ancestry/relatedness. At a minimum, use ~10 principal components as covariates to correct for population stratification and include principal components as indicated in the analysis models below. If you do not use rvtests, your results may not be usable for conditional analyses and aggregated analyses of rare variants. If in doubt, we are happy to advise. Please indicate in the Excel file requested below the method used to account for ancestry/relatedness.\n1.\u00a0\u00a0\u00a0\u00a0\u00a0Summary level statistics for meta-analysis of variant associations\nThe following summary level statistics will be generated and shared for meta-analysis of variant associations, ideally using rvtests. rvtests requires an indexed VCF file (for genotypes), a PED file (for phenotypes) as input. Instructions below are for rvtests. If you are using a different method, please contact us.\ni.\nBasic VCF metrics\n, including reference and alternative alleles, chromosome positions and strand. These statistics are not directly used in the computation of the variant tests but are needed for interpretation and meta-analysis.\nii.\nAllele frequency for each variant\niii.\nSingle variant association test statistics, including direction of effect.\nWe use score statistics calculated at each variant site. Another possible option would be to share estimates of genetic effects \u2013 but, when variant frequencies are low, score statistics are more numerically stable and preferred.\niv.\nCovariance matrix for each genetic region.\nWe compute the genotype covariance for all variants in a sliding window, with a width of 500,000 base pairs. This matrix reflects linkage disequilibrium in the region and will be used for meta-analysis of aggregate region- or gene-based tests of rare/low-frequency variation.\n2. Indexing the VCF files\nrvtest works with tabix, and takes indexed bgzipped VCF files as input.\nIf your VCF file is not compressed with bgzip please use the following command\n(grep ^\"#\" $your_old_vcf; grep -v ^\"#\" $your_old_vcf | sed 's:^chr::ig' | sort -k1, 1n -k2, 2n) | bgzip -c > $your_vcf_file\nPlease index your bgzip compressed VCF files using the following command:\ntabix -f -p vcf $your_vcf_file\nPlease make sure there are no entries with -1\u2019s or 0\u2019s in the chromosome number column.\n3. Specify VCF files\nYou should use --inVcf\u00a0$your_vcf_file to specify which VCF to use.\n4. Specify phenotypes\nThe rvtest tool requires a simple pedigree file that starts with the standard 5 columns (family id, individual id, father id, mother id and sex) followed by trait or trait residuals.\nYou can use --mpheno $phenoypeColumnNumber or --pheno-name to specify a given phenotype.\nAn example phenotype file, (example.pheno), has the following format:\nfid iid fatid matid sex y1 y2 y3 y4\nP1 P1 0 0 0 1.7642934435605 -0.733862638327895 -0.980843608339726 1\nP2 P2 0 0 0 0.457111744989746 0.623297281416372 -2.24266162284447 0\nP3 P3 0 0 0 0.566689682543218 1.44136462889459 -1.6490100777089 0\nP4 P4 0 0 0 0.350528353203767 -1.79533911725537 -1.11916876241804 0\nP5 P5 0 0 1 2.72675074738545 -1.05487747371158 -0.33586430010589 1\nPhenotype file is specified by the option --pheno example.pheno. The default phenotype column header is \u201cy1\u201d. If you want to use alternative columns as phenotype for association analysis (e.g the column with header y2), you may specific the header names using either\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0--mpheno 2 or\n\u00b7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0--pheno-name y2\nNOTE:\nto use \u201c--pheno-name\u201d the header line must start with \u201cfid iid\u201d as PLINK requires.\nIn phenotype file, missing values can be denoted by NA or any non-numeric value. Individuals with missing phenotypes will be automatically dropped from subsequent association analysis. For each missing phenotype value, a warning will be generated and recorded in the log file.\nOptional: If using rvtests for phenotype transformation:\nIf you would like to calculate residuals using the rvtest software please refer to the covariates that need to be included for each trait as described in the phenotype transformation step and use\u00a0--covar and --covar-name options to designate covariates, and the --inverseNormal and --useResidualAsPhenotype while performing the analysis.\nThe covariate file, (e.g. example.covar) has a similar format as the phenotype file, e.g.:\nfid iid age bmi covCenter1 covCenter2 covCenter3\nP1 P1 23 24.2 1 0 0\nP2 P2 32 29.0 0 1 0\nP3 P3 44 32.4 0 0 1\nP4 P4 25 28.2 1 0 0\nNOTE: Missing data in the covariate file can be labeled by any non-numeric value (e.g. NA). Missing values will automatically be imputed to the mean value in analysis.\n5. Generate kinship matrices\nWe ask all studies to use an\nempirical kinship matrix (aka genomic relationship matrix)\nfor use in analysis with rvtests. If you do not already have a kinship matrix for your study it can be generated with rvtests.\nKinship matrices are needed\nfor all studies\nto account for familial relatedness, cryptic relatedness, and population stratification. rvtests generates an empirical kinship matrix from the VCF file. Within the rvtests folder there is a script called \u201cvcf2kinship\u201d. However, we want to run it on all common markers (MAF \u2265 5%) genome-wide so we first must create a concatenated VCF file from all chromosomes.\u00a0\u00a0If this step is still too slow, you may want to further prune the VCF file with MAF \u2265 5% markers to include only genotyped variants \u2013 please contact us if you need advice on this step.\n# Concatenate per-chromosome imputed polymorphic genotypes VCF files into single VCF file\n(zcat yourvcffile.HRCimputed.chr1.imputed.poly.vcf.gz;\nzgrep -v '^#' yourvcffile.HRCimputed.chr2.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr3.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr4.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr5.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr6.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr7.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr8.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr9.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr10.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr11.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr12.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr13.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr14.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr15.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr16.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr17.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr18.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr19.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr20.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr21.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chr22.imputed.poly.vcf.gz; \\\nzgrep -v '^#' yourvcffile.HRCimputed.chrX.reordered.imputed.poly.vcf.gz) | bgzip -c > yourvcffile.HRCimputed.chrALL.imputed.poly.vcf.gz\nThis will effectively duplicate the imputed genotype data. If disk space is a concern, this alternative requires less storage space by keeping only variants above 5%. Use this for creating the kinship matrix, but the full polymorphic VCFs for association.\n(bcftools view \u2013q 0.05:minor yourvcffile.HRCimputed.chr1.imputed.poly.vcf.gz -O u ; \\\nbcftools view \u2013q 0.05:minor yourvcffile.HRCimputed.chr2.imputed.poly.vcf.gz -O u \\\n| zgrep -v '^#'; \\\n[ditto through chr3-22]\nbcftools view \u2013q 0.05:minor yourvcffile.HRCimputed.chrX.imputed.poly.vcf.gz -O u \\\n| zgrep -v '^#') \\\n| bgzip \u2013c > yourvcffile.HRCimputed.chrALL.imputed.mafge5pct.vcf.gz\n### Generate kinship matrix (--threads controls the number of parallel threads, adjust as needed)\n#!/bin/bash\nvcf2kinship --inVcf\u00a0yourvcffile.HRCimputed.chrALL.imputed.poly.vcf.gz \\\n-- ped yourpedfile.ped \\\n--bn \\ #balding-nichols method\n--out kinship_matrix \\ #output file name prefix\n--xLabel X \\ #Label we used for the X chromosome\n--xHemi \\ #create kinship for hemizygous region\n--minMAF .05 \\ #min MAF of variants that contribute to the kinship matrix\n--thread 12\nNOTE:\nvcf2kinship\nwill produce a warning message if there are heterozygous genotype calls present for males in the hemizygous region, and then sets these genotypes to missing to produce the kinship matrix.\u00a0These samples should have been removed \u2013 see section 2.3 above.\n6. Exemplar command:\nThe following are example commands for using rvtests to generate score statistics and covariance matrices. It can be used if you have previously generated residuals that have been inverse normally transformed or if you are using rvtests to generate residuals and perform the inverse normal transformation.\nBrief example:\nrvtests --inVcf input.vcf --pheno phenotype.ped --pheno-name HT_INV --out output --kinship kinship_matrix --meta score,cov[windowSize=500000] --dosage DS\nIMPORTANT NOTE: The [windowSize=500000] option is shell-specific. It works in bash, but not in csh. It may not work in other Unix shells. Therefore, we recommend running all rvtest jobs in a bash shell.\nAnalyses will loop through chromosomes\nMany of the steps in this analysis plan will be done chromosome by chromosome. One very easy way to run by chromosome is with a\nfor\nloop in bash or c-shell.\u00a0An example is provided below; modify as appropriate for the phenotypes, sexes, and ancestries available in your study, the panel(s) being used for imputation, and for job submission with your compute resources.\nNOTE: Some of these lines are not used if you have already generated residuals and performed inverse normal transformation. These are indicated in red. If using rvtest to generate residuals, input covariates are not consistent for all analyses.\nFor chrX, male genotypes in rvtest can be coded as 0, 1, 0/0, or 1/1, and dosages should be between 0 and 1. rvtest will convert these to a 0-2 scale automatically in analysis. rvtest already has preset values for the pseudo-autosomal regions (PAR), and properly adjusts analysis accordingly. rvtest will perform analysis on both PAR and non-PAR regions, but only calculates HWE and alleles counts in females for non-PAR regions. rvtest association analysis should be conducted on polymorphic variants only.\n#!/bin/bash\n#replace the following variables and values as needed to match traits, ancestries, sexes, and reference panels available for your study\n###trait=TC_INV, logTG_INV, HDL_INV, LDL_INV, TC_RAW, logTG_RAW, HDL_RAW, LDL_RAW, Height, BMI, WHRadjBMI, WHRunadjusted\n###ancestry=EUR,\nAFR, AMR, SAS, EAS\n###sex=MEN,WOMEN,ALL\n###panel=1KGP3,HRC\nfor i in `1 22` X; do #Loop over chromosomes\nrvtest --inVcf yourvcffile.${panel}.chr${i}.imputed.poly.vcf.gz \\ #Input vcf\n--pheno study_${ancestry}_pheno.ped \\ #Input phenotype ped file\n--pheno-name ${trait} \\ #Name the phenotype column in the phenotype ped file\n--meta score,cov[windowSize=500000]\n\\ #Generate single variant score test\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#and genotype covariance matrix with a window size of 500kb around\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#each variant. Use for only largest N trait (cases and controls)\n--meta score \\ #Use for all other traits (does not generate covariance matrix)\n--kinship kinship_matrix.kinship \\\n--covar study_${ancestry}_cov.ped \\ #Name of covariate file, if using one\n--covar-name sex, age, age2, \\ #Names of covariates only if using covariates (that is, if\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#residuals not already calculated and inverse normal transformed)\n--useResidualsAsPhenotype \\ #Residualize before testing variants only if not already\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#calculated\n--inverseNormal \\ #Inverse normalize the residual distribution only if not already\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#calculated\n--xLabel\n\\ #Flag can be added if chrX is coded other than X in VCF (e.g. 23)\n--xHemiKinship kinship_matrix.xHemiKinship \\ #use instead of --kinship to indicate\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0#chrX analysis\n--dosage DS \\ #Specify vcf dosage field\n--out STUDY_${ancestry}_${panel}_imputation_${trait}_chr${i}\ndone\nCombine your results files\nThe following example command, corresponding to the outputs from the example command provided above, will concatenate all per-chromosome results into one output file for each ancestry x trait combination. For other reference panels, phenotypes, etc. please modify as appropriate.\nPlease combine the set of score test results and the covariance matrix files across chromosomes to generate a single cumulative file across all autosomes for each data type (i.e., 1 metaScore file including all autosomes and 1 metaCov file for all autosomes). Keep and upload chrX separate from the autosomes.\u00a0You will only upload one metaCov file in total (not one per trait, see File Naming and Uploading in section 8, below.)\n# Concatenate association results into a single file\n#!/bin/bash\n### trait=TC_INV, logTG_INV, HDL_INV, LDL_INV, TC_RAW, logTG_RAW, HDL_RAW, LDL_RAW, Height, BMI, WHRadjBMI, WHRunadjusted\n###ancestry=EUR,AFR,AMR,SAS,EAS #replace this as needed with the appropriate ancestry\n###sex=MEN,WOMEN,ALL\n###panel=1KGP3,HRC\n(\nzgrep -E -h\u00a0'^1\\s|#|CHROM' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr1.MetaScore.assoc.gz; \\\nzgrep -E -h '^2\\s'\u00a0STUDY_${ancestry}_${panel}_${trait}_${sex}_chr2.MetaScore.assoc.gz; \\\nzgrep -E -h '^3\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr3.MetaScore.assoc.gz; \\\nzgrep -E -h '^4\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr4.MetaScore.assoc.gz; \\\nzgrep -E -h '^5\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr5.MetaScore.assoc.gz;\\\nzgrep -E -h\u00a0'^6\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr6.MetaScore.assoc.gz; \\\nzgrep -E -h '^7\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr7.MetaScore.assoc.gz; \\\nzgrep -E -h '^8\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr8.MetaScore.assoc.gz; \\\nzgrep -E -h '^9\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr9.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^10\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr10.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^11\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr11.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^12\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr12.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^13\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr13.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^14\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr14.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^15\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr15.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^16\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr16.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^17\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr17.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^18\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr18.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^19\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr19.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^20\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr20.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^21\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr21.MetaScore.assoc.gz; \\\nzgrep -E -h\u00a0'^22\\s' STUDY_${ancestry}_${panel}_${trait}_${sex}_chr22.MetaScore.assoc.gz; \\\nzgrep \u2013E \u2013h \u2018^X\\s\u2019 STUDY_${ancestry}_${panel}_${trait}_${sex}_chrX.MetaScore.assoc.gz)\u00a0| bgzip -c > STUDY_${ancestry}_${panel}_${trait}_${sex}_STATUS_DATE_ANALYST_ANALYSIS.MetaScore.assoc.gz\nThen, for the trait with the largest sample size, merge the *.MetaCov.assoc.gz files.\nThere will be one covariance matrix per ancestry, and separate matrices if analyses were separated into cases and controls.\n7. Output Files\nrvtest will generate three files for sharing. The first has the summary statistics (from single variant score tests); the second has linkage disequilibrium (LD) matrices summarizing covariance between single marker score statistics, and the third provides a log file with all parameter settings. These three files are required for central meta-analysis and QC.\nUsing \u201c--out\noutput\n\u201d options, the results are stored in\noutput.MetaScore.assoc\nand\noutput.MetaCov.assoc.gz\n. Each output file contains a header with summaries of trait and covariates.\nThe file\noutput.MetaScore.assoc.gz\nfile contains the following columns:\nCHROM, POS, REF, ALT: chromosome name, position, reference allele and alternative allele\nN_INFORMATIVE: number of samples in the analysis\nAF: allele frequency\nINFORMATIVE_ALT_AC: number of alternative alleles\nCALL_RATE: fraction of non-missing genotypes\nHWE_PVALUE: Hardy-Weinberg Equilibrium P-value.\nN_REF, N_HET, N_ALT: number of reference/reference, reference/alternative, alternative/alternative genotypes respectively.\nU_STAT, SQRT_V_STAT: U statistic and square root of V statistic as in the score test.\nALT_EFFSIZE: estimated effect size using alternative allele.\nPVALUE: P-value when testing genetic association using score test.\nThe\noutput.MetaCov.assoc.gz\ncontains following columns:\nCHROM: Chromosome name\nSTART_POS, END_POS: Chromosomal positions of the first and the last variant in the sliding window.\nNUM_MARKER: number of variants in the sliding window.\nMARKER_POS: variant chromosomal positions in the sliding window.\nCOV: covariance for each pair of test statistics in the sliding window."
        },
        {
            "header": "Troubleshooting",
            "content": ""
        },
        {
            "header": "Time Taken",
            "content": ""
        },
        {
            "header": "Anticipated Results",
            "content": ""
        },
        {
            "header": "References",
            "content": ""
        }
    ],
    "attributes": {
        "acceptedTermsAndConditions": true,
        "allowDirectSubmit": true,
        "archivedVersions": [],
        "articleType": "Method Article",
        "associatedPublications": [],
        "authors": [
            {
                "id": 59294410,
                "identity": "d6bc1b8f-2bbb-45b9-98d2-62d8098963ee",
                "order_by": 0,
                "name": "Cristen Willer",
                "email": "cristen@umich.edu",
                "orcid": "",
                "institution": "",
                "correspondingAuthor": true,
                "prefix": "",
                "firstName": "Cristen",
                "middleName": "",
                "lastName": "Willer",
                "suffix": ""
            }
        ],
        "badges": [],
        "createdAt": "2021-10-26 16:43:45",
        "currentVersionCode": 1,
        "declarations": "",
        "doi": "10.21203/rs.3.pex-1687/v1",
        "doiUrl": "https://doi.org/10.21203/rs.3.pex-1687/v1",
        "draftVersion": [],
        "editorialEvents": [],
        "editorialNote": "",
        "failedWorkflow": [],
        "files": [
            {
                "id": 15980122,
                "identity": "fb8e3183-54a5-4de4-b2cc-ec8239c09a00",
                "added_by": "auto",
                "created_at": "2021-11-29 18:52:53",
                "extension": "pdf",
                "order_by": 0,
                "title": "",
                "display": "",
                "copyAsset": false,
                "role": "manuscript-pdf",
                "size": 586673,
                "visible": true,
                "origin": "",
                "legend": "",
                "description": "",
                "filename": "manuscript.pdf",
                "url": "https://assets.researchsquare.com/files/pex-1687/v1/dd9d6a1a-abdf-47ca-9eea-5dad4f8dd7d6.pdf"
            }
        ],
        "financialInterests": "",
        "fulltextSource": "",
        "fullText": "",
        "funders": [],
        "hasOptedInToPreprint": true,
        "hasPassedJournalQc": "",
        "hideJournal": true,
        "highlight": "",
        "institution": "",
        "isAuthorSuppliedPdf": false,
        "isDeskRejected": "",
        "isHiddenFromSearch": false,
        "isInQc": false,
        "isInWorkflow": false,
        "journal": {
            "display": true,
            "email": "protocol.exchange@nature.com",
            "identity": "protocol-exchange",
            "isNatureJournal": false,
            "hasQc": false,
            "allowDirectSubmit": true,
            "externalIdentity": "",
            "sideBox": "",
            "submissionUrl": "https://protocolexchange.researchsquare.com/submission",
            "title": "Protocol Exchange",
            "twitterHandle": ""
        },
        "keywords": "GLGC, GWAS, Lipids, meta-analysis, cholesterol",
        "license": {
            "name": "CC BY 4.0",
            "url": "https://creativecommons.org/licenses/by/4.0/"
        },
        "manuscriptAbstract": "<p>This protocol describes the guidelines for generating GWAS summary statistics that were provided to all participating cohorts in the Global Lipids Genetics Consortium HRC + 1KGP3 imputation meta-analysis collected jointly with the GIANT consortium.  It is applicable for generating the input phenotype and genotype files for use with the rvtests software.  Key stages include imputation, generating phenotype files, and running the analysis to generate summary statistics.  The exact time needed to carry out this protocol varies depending on the existing genotype files and size of the cohort. The latest version of rvtests is available at: http://zhanxw.github.io/rvtests/</p><p><br></p>",
        "manuscriptTitle": "Analysis plan for primary cohort GWAS for blood lipid levels for the Global Lipids Genetics Consortium",
        "msid": "",
        "msnumber": "",
        "nonDraftVersions": [
            {
                "code": 1,
                "date": "2021-11-29 18:52:48",
                "doi": "10.21203/rs.3.pex-1687/v1",
                "editorialEvents": [
                    {
                        "type": "communityComments",
                        "content": 0
                    }
                ],
                "status": "published",
                "journal": {
                    "display": true,
                    "email": "info@researchsquare.com",
                    "identity": "researchsquare",
                    "isNatureJournal": false,
                    "hasQc": true,
                    "allowDirectSubmit": true,
                    "externalIdentity": "",
                    "sideBox": "",
                    "submissionUrl": "/submission",
                    "title": "Research Square",
                    "twitterHandle": "researchsquare"
                }
            }
        ],
        "origin": "",
        "ownerIdentity": "5f464bc2-7532-454f-98fb-598fedbfb9a1",
        "owner": [],
        "postedDate": "November 29th, 2021",
        "published": true,
        "revision": "",
        "status": "posted",
        "subjectAreas": [
            {
                "id": 8824146,
                "name": "Genetics"
            }
        ],
        "tags": [],
        "versionOfRecord": [],
        "versionCreatedAt": "2021-11-29 18:52:48",
        "video": "",
        "vorDoi": "",
        "vorDoiUrl": "",
        "workflowStages": []
    }
}